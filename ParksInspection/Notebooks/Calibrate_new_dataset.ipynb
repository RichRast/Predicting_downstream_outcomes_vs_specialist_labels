{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bd915b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c18f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import torch\n",
    "import pdb\n",
    "import random\n",
    "import tables\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, average_precision_score,\\\n",
    "balanced_accuracy_score\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "from dill.source import getsource\n",
    "from dill import detect\n",
    "import functools\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca226e47",
   "metadata": {},
   "source": [
    "### set the seeds and change to current directory + set the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=90210\n",
    "np.random.seed(SEED)\n",
    "os.environ['USER_PATH']='/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/'\n",
    "os.environ['OUT_PATH']='/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/output_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648e3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/')\n",
    "from AnalysisFuncs import trainEvalModel, trainHardPseudo, plotCalibrationPlots, getClippedProbs\n",
    "from AnalysisFuncs import saveFile, loadFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a06c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3ce23",
   "metadata": {},
   "source": [
    "### Create function to pickle functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a67747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_string(fn):\n",
    "    return getsource(detect.code(fn)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75551144",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path=osp.join(os.environ.get('OUT_PATH'), 'ParksInspection','New_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a897016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = loadFile(osp.join(processed_data_path,'predict_T'), '/train_X.npy')\n",
    "train_y_T = loadFile(osp.join(processed_data_path,'predict_T'), '/train_y_T.npy')\n",
    "val_X = loadFile(osp.join(processed_data_path,'predict_T'), '/val_X.npy')\n",
    "val_y_T = loadFile(osp.join(processed_data_path,'predict_T'), '/val_y_T.npy')\n",
    "train_cross_val_X = loadFile(osp.join(processed_data_path,'predict_T'), '/train_cross_val_X.npy')\n",
    "train_cross_val_y_T = loadFile(osp.join(processed_data_path,'predict_T'), '/train_cross_val_y_T.npy')\n",
    "test_X = loadFile(osp.join(processed_data_path,'predict_T'), '/test_X.npy')\n",
    "test_y_T = loadFile(osp.join(processed_data_path,'predict_T'), '/test_y_T.npy')\n",
    "\n",
    "train_X_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/train_X_D_given_T.npy')\n",
    "train_y_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/train_y_D_given_T.npy')\n",
    "val_X_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/val_X_D_given_T.npy')\n",
    "val_y_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/val_y_D_given_T.npy')\n",
    "train_cross_val_X_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), \n",
    "                                       '/train_cross_val_X_D_given_T.npy')\n",
    "train_cross_val_y_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), \n",
    "                                       '/train_cross_val_y_D_given_T.npy')\n",
    "test_X_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/test_X_D_given_T.npy')\n",
    "test_y_D_given_T = loadFile(osp.join(processed_data_path,'predict_D_given_T'), '/test_y_D_given_T.npy')\n",
    "\n",
    "\n",
    "\n",
    "train_y_D_and_T = loadFile(osp.join(processed_data_path,'predict_D_and_T'), '/train_y_D_and_T.npy')\n",
    "val_y_D_and_T = loadFile(osp.join(processed_data_path,'predict_D_and_T'), '/val_y_D_and_T.npy')\n",
    "train_cross_val_y_D_and_T = loadFile(osp.join(processed_data_path,'predict_D_and_T'), \n",
    "                                       '/train_cross_val_y_D_and_T.npy')\n",
    "test_y_D_and_T = loadFile(osp.join(processed_data_path,'predict_D_and_T'), '/test_y_D_and_T.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6145770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train %:64.01, val %:15.99, test %:19.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rr568/.conda/envs/icu-benchmark/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "# load df_cleaned and test_idxs\n",
    "df_cleaned = loadFile(processed_data_path, 'df_cleaned.csv')\n",
    "test_idxs = loadFile(processed_data_path, '/test_idxs.npy')\n",
    "train_idxs = loadFile(processed_data_path, '/train_idxs.npy')\n",
    "val_idxs = loadFile(processed_data_path, '/val_idxs.npy')\n",
    "assert len(np.intersect1d(train_idxs, val_idxs))==0\n",
    "assert len(np.intersect1d(test_idxs, val_idxs))==0\n",
    "assert len(np.intersect1d(train_idxs, test_idxs))==0\n",
    "tr=len(train_idxs)\n",
    "v=len(val_idxs)\n",
    "t=len(test_idxs)\n",
    "print(f\"train %:{tr*100/(tr+v+t):.2f}, val %:{v*100/(tr+v+t):.2f}, test %:{t*100/(tr+v+t):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9898931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best params as pickle if they exist , if not use the default settings\n",
    "random_state=0\n",
    "bst_params_T_LR={'random_state': random_state, \n",
    "              'solver': 'liblinear', \n",
    "              'penalty':  'l1',\n",
    "                }\n",
    "bst_params_T_LGBM={'random_state': random_state, \n",
    "                  }\n",
    "LR_T = LogisticRegression(**bst_params_T_LR)\n",
    "LGBM_T = LGBMClassifier(**bst_params_T_LGBM)\n",
    "\n",
    "bst_params_D_given_T_LR = {'random_state': random_state, \n",
    "                      'solver': 'liblinear', \n",
    "                      'penalty':  'l1',\n",
    "                       }\n",
    "# bst_params_D_given_T_LGBM={'random_state': random_state, \n",
    "#                   }\n",
    "bst_params_D_given_T_LGBM = {'bagging_fraction': 0.9834006751148752, \n",
    "             'feature_fraction': 0.7609241608750359, 'max_depth': 7, 'min_child_samples': 50}\n",
    "\n",
    "LR_D_given_T = LogisticRegression(**bst_params_D_given_T_LR)\n",
    "LR_D_given_T_ipw = LogisticRegression(**bst_params_D_given_T_LR)\n",
    "LGBM_D_given_T = LGBMClassifier(**bst_params_D_given_T_LGBM)\n",
    "LGBM_D_given_T_ipw = LGBMClassifier(**bst_params_D_given_T_LGBM)\n",
    "bst_params_D_and_T_LR = {'random_state': random_state, \n",
    "                      'solver': 'liblinear', \n",
    "                      'penalty':  'l1',\n",
    "                     }\n",
    "bst_params_D_and_T_LGBM={'random_state': random_state, \n",
    "                  }\n",
    "LR_D_and_T = LogisticRegression(**bst_params_D_and_T_LR)\n",
    "LGBM_D_and_T = LGBMClassifier(**bst_params_D_and_T_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7311f6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/output_directory/ParksInspection/New_Dataset/sigmoid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrate_method='sigmoid'\n",
    "#use calibration method in the path to save the model\n",
    "processed_data_path = osp.join(processed_data_path, calibrate_method)\n",
    "processed_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f0984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167823, 337), (41941, 337), 209764)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cross_val_X.shape, test_X.shape, train_cross_val_X.shape[0]+test_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa56b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score :predicting T using Logistic Regression: 0.951\n",
      "AUPR score :predicting T using Logistic Regression: 0.934\n",
      "AUC score :predicting T using LGBM: 0.963\n",
      "AUPR score :predicting T using LGBM: 0.951\n"
     ]
    }
   ],
   "source": [
    "model_descr=\"predicting T using Logistic Regression\"\n",
    "LR_T, test_proba_LR_T = trainEvalModel(LR_T, train_cross_val_X.copy(), train_cross_val_y_T.copy(), \n",
    "                                       test_X.copy(), test_y_T.copy(), \n",
    "                                       model_descr, calibrate=True, calibrate_method=calibrate_method)\n",
    "model_descr=\"predicting T using LGBM\"\n",
    "LGBM_T, test_proba_LGBM_T = trainEvalModel(LGBM_T, train_cross_val_X.copy(), train_cross_val_y_T.copy(),\n",
    "                                           test_X.copy(), test_y_T.copy(), \n",
    "                                       model_descr, calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98cf20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "saveFile(osp.join(processed_data_path,'predict_T'), LR_T, 'LR_T.pkl')\n",
    "saveFile(osp.join(processed_data_path,'predict_T'), LGBM_T, 'LGBM_T.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0bb8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score :predicting D|T using Logistic Regression: 0.677\n",
      "AUPR score :predicting D|T using Logistic Regression: 0.541\n"
     ]
    }
   ],
   "source": [
    "model_descr=\"predicting D|T using Logistic Regression\"\n",
    "LR_D_given_T, test_proba_LR_D_given_T = trainEvalModel(LR_D_given_T, train_cross_val_X_D_given_T.copy(), \n",
    "                    train_cross_val_y_D_given_T.copy(), test_X_D_given_T.copy(), test_y_D_given_T.copy(),\n",
    "                                        model_descr, calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e37ccb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "AUC score :predicting D|T using LGBM: 0.687\n",
      "AUPR score :predicting D|T using LGBM: 0.559\n"
     ]
    }
   ],
   "source": [
    "model_descr=\"predicting D|T using LGBM\"\n",
    "LGBM_D_given_T, test_proba_LGBM_D_given_T = trainEvalModel(LGBM_D_given_T, train_cross_val_X_D_given_T.copy(), \n",
    "                    train_cross_val_y_D_given_T.copy(), test_X_D_given_T.copy(), test_y_D_given_T.copy(),\n",
    "                                            model_descr, calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6536dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFile(osp.join(processed_data_path,'predict_D_given_T'), LR_D_given_T, 'LR_D_given_T.pkl')\n",
    "saveFile(osp.join(processed_data_path,'predict_D_given_T'), LGBM_D_given_T, 'LGBM_D_given_T.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc1595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score :predicting D,T using Logistic Regression: 0.843\n",
      "AUPR score :predicting D,T using Logistic Regression: 0.485\n",
      "AUC score :predicting D,T using LGBM: 0.850\n",
      "AUPR score :predicting D,T using LGBM: 0.504\n"
     ]
    }
   ],
   "source": [
    "model_descr=\"predicting D,T using Logistic Regression\"\n",
    "LR_D_and_T, test_proba_LR_D_and_T = trainEvalModel(LR_D_and_T, train_cross_val_X.copy(), \n",
    "                    train_cross_val_y_D_and_T.copy(), test_X.copy(), test_y_D_and_T.copy(),\n",
    "                                        model_descr, calibrate=True, calibrate_method=calibrate_method)\n",
    "model_descr=\"predicting D,T using LGBM\"\n",
    "LGBM_D_and_T, test_proba_LGBM_D_and_T = trainEvalModel(LGBM_D_and_T, train_cross_val_X.copy(), \n",
    "                    train_cross_val_y_D_and_T.copy(), test_X.copy(), test_y_D_and_T.copy(),\n",
    "                                        model_descr, calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2795b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFile(osp.join(processed_data_path,'predict_D_and_T'), LR_D_and_T, 'LR_D_and_T.pkl')\n",
    "saveFile(osp.join(processed_data_path,'predict_D_and_T'), LGBM_D_and_T, 'LGBM_D_and_T.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91dcecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV(base_estimator=LGBMClassifier(boosting_type='gbdt',\n",
      "                                                     class_weight=None,\n",
      "                                                     colsample_bytree=1.0,\n",
      "                                                     importance_type='split',\n",
      "                                                     learning_rate=0.1,\n",
      "                                                     max_depth=-1,\n",
      "                                                     min_child_samples=20,\n",
      "                                                     min_child_weight=0.001,\n",
      "                                                     min_split_gain=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=-1, num_leaves=31,\n",
      "                                                     objective=None,\n",
      "                                                     random_state=0,\n",
      "                                                     reg_alpha=0.0,\n",
      "                                                     reg_lambda=0.0,\n",
      "                                                     silent=True, subsample=1.0,\n",
      "                                                     subsample_for_bin=200000,\n",
      "                                                     subsample_freq=0),\n",
      "                       cv=5, method='sigmoid')\n"
     ]
    }
   ],
   "source": [
    "print(LGBM_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdc28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_descr=\"predicting D|T_IPW using Logistic Regression\"\n",
    "# pass dataframe and create D_given_T again\n",
    "train_X_D_given_T_probs_LR, train_cross_val_X_ipw = getClippedProbs(LR_T,\n",
    "                                            train_cross_val_X.copy(), train_cross_val_y_T.copy())\n",
    "np.testing.assert_array_equal(train_cross_val_X_ipw, train_cross_val_X_D_given_T)\n",
    "LR_D_given_T_ipw, test_proba_LR_D_given_T_ipw = trainEvalModel(LR_D_given_T_ipw, train_cross_val_X_ipw, \n",
    "                    train_cross_val_y_D_given_T, test_X_D_given_T.copy(), test_y_D_given_T.copy(),\n",
    "                    model_descr, calibrate=True, calibrate_method=calibrate_method,\n",
    "                    sample_weight=1/train_X_D_given_T_probs_LR.copy())\n",
    "model_descr=\"predicting D|T_IPW using LGBM\"\n",
    "train_X_D_given_T_probs_LGBM, train_cross_val_X_ipw = getClippedProbs(LGBM_T, \n",
    "                                        train_cross_val_X.copy(), train_cross_val_y_T.copy())\n",
    "LGBM_D_given_T_ipw, test_proba_LGBM_D_given_T_ipw = trainEvalModel(LGBM_D_given_T_ipw, train_cross_val_X_ipw,\n",
    "                    train_cross_val_y_D_given_T,\n",
    "                    test_X_D_given_T.copy(), test_y_D_given_T.copy(),\n",
    "                    model_descr, calibrate=True, calibrate_method=calibrate_method,\n",
    "                    sample_weight=1/train_X_D_given_T_probs_LGBM.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0144b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFile(osp.join(processed_data_path,'predict_D_given_T_ipw'), LR_D_given_T_ipw, 'LR_D_given_T_ipw.pkl')\n",
    "saveFile(osp.join(processed_data_path,'predict_D_given_T_ipw'), LGBM_D_given_T_ipw, 'LGBM_D_given_T_ipw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2730ad",
   "metadata": {},
   "source": [
    "#### Hard PseudoLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27ae1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0\n",
    "bst_params_D_pseudo_LR = bst_params_D_given_T_LR\n",
    "bst_params_D_pseudo_LGBM = bst_params_D_given_T_LGBM\n",
    "LR_D_pseudo = LogisticRegression(**bst_params_D_pseudo_LR)\n",
    "LGBM_D_pseudo = LGBMClassifier(**bst_params_D_pseudo_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e51ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score :Logistic Regression with hard pseudo labels: 0.672\n",
      "AUPR score :Logistic Regression with hard pseudo labels: 0.537\n"
     ]
    }
   ],
   "source": [
    "#predict the outcomes\n",
    "#assert that the pseudo labels are only binary in nature and not probs\n",
    "train_cross_val_idxs=np.concatenate((train_idxs, val_idxs))\n",
    "LR_D_pseudo, test_probs_D_pseudo_LR = trainHardPseudo(deepcopy(LR_D_given_T), df_cleaned.copy(), train_idxs.copy(), \n",
    "                        val_idxs.copy(), train_X.copy(), val_X.copy(), deepcopy(LR_D_given_T), \n",
    "                        test_X_D_given_T.copy(), test_y_D_given_T.copy(), \n",
    "        model_descr=\"Logistic Regression with hard pseudo labels\", calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73ec4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9834006751148752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9834006751148752\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7609241608750359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609241608750359\n",
      "AUC score :LGBM with hard pseudo labels: 0.679\n",
      "AUPR score :LGBM with hard pseudo labels: 0.546\n"
     ]
    }
   ],
   "source": [
    "LGBM_D_pseudo, test_probs_D_pseudo_LGBM = trainHardPseudo(deepcopy(LGBM_D_given_T), df_cleaned.copy(), \n",
    "                        train_idxs.copy(), val_idxs.copy(),\n",
    "                        train_X.copy(), val_X.copy().copy(), deepcopy(LGBM_D_given_T), test_X_D_given_T.copy(), \n",
    "                        test_y_D_given_T.copy(), \n",
    "                        model_descr=\"LGBM with hard pseudo labels\", calibrate=True, calibrate_method=calibrate_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "428e1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "saveFile(osp.join(processed_data_path,'predict_D_pseudo'), LR_D_pseudo, 'LR_D_pseudo.pkl')\n",
    "saveFile(osp.join(processed_data_path,'predict_D_pseudo'), LGBM_D_pseudo, 'LGBM_D_pseudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c1ee4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167823, 337)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cross_val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3ce095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167823,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cross_val_y_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acabf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68b195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu-benchmark",
   "language": "python",
   "name": "icu-benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

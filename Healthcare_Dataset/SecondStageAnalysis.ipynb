{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bd915b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c18f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import torch\n",
    "import pdb\n",
    "import random\n",
    "import tables\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, average_precision_score,\\\n",
    "balanced_accuracy_score\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "from dill.source import getsource\n",
    "from dill import detect\n",
    "import functools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca226e47",
   "metadata": {},
   "source": [
    "### set the seeds and change to current directory + set the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=90210\n",
    "np.random.seed(SEED)\n",
    "os.environ['USER_PATH']='/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/'\n",
    "os.environ['OUT_PATH']='/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/output_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/share/pierson/selective_labels_data/hirid_data_analysis/richras_dir/learning_from_doctor_and_patient/')\n",
    "from AnalysisFuncs import plotCorr, getPred_fromProb, getMetrics, getCorr, getGroundTruth, getURange\n",
    "from AnalysisFuncs import getResiduals, plotDistributionProbs, plotCorr_w_Unobs, trainHardPseudo\n",
    "from AnalysisFuncs import saveFile, loadFile, plotCalibrationPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b68044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3ce23",
   "metadata": {},
   "source": [
    "### Create function to pickle functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75551144",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path=osp.join(os.environ.get('USER_PATH'), 'HIRID_Repo', 'logs', 'benchmark_exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_second_stage = loadFile(osp.join(processed_data_path,  'LGBM_w_feat_v2_cutoff_T', 'secondStage'),\n",
    "                              'train_second_stage.pkl')\n",
    "test_second_stage = loadFile(osp.join(processed_data_path,  'LGBM_w_feat_v2_cutoff_T', 'secondStage'), \n",
    "                             'test_second_stage.pkl')\n",
    "test_X = loadFile(osp.join(processed_data_path,'LGBM_w_feat_v2_cutoff_T', \n",
    "                '_depth_7_subsample-data_1.0_subsample-feat_1.0', 'Lactate_Measured', '1111'), 'test_rep.pkl')\n",
    "calibrated_p_T = loadFile(osp.join(processed_data_path,'probs_T'), '/probs.npy')\n",
    "calibrated_p_D_T1 = loadFile(osp.join(processed_data_path,'probs_D|T'), '/probs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that these are indeed the calibrated probabilities \n",
    "fig1,ax1 = plt.subplots()\n",
    "fig2, ax2 = plt.subplots()\n",
    "test_y_T = loadFile(osp.join(processed_data_path,'LGBM_w_feat_v2_cutoff_T', \n",
    "                '_depth_7_subsample-data_1.0_subsample-feat_1.0', 'Lactate_Measured', '1111'), 'test_label.pkl')\n",
    "plotCalibrationPlots(calibrated_p_T, test_y_T, None, 'T', ax1, ax2, n_bins=10)\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdcd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,ax1 = plt.subplots()\n",
    "fig2, ax2 = plt.subplots()\n",
    "test_y_D_given_T = loadFile(osp.join(processed_data_path,'LGBM_w_feat_v2_cutoff_T', \n",
    "            '_depth_7_subsample-data_1.0_subsample-feat_1.0', 'Lactate_Above_Threshold', '1111'), 'test_label.pkl')\n",
    "plotCalibrationPlots(calibrated_p_D_T1[test_y_T==1], test_y_D_given_T, None, 'D|T', ax1, ax2, n_bins=10)\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb455da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = loadFile(osp.join(processed_data_path,'LGBM_w_feat_v2_cutoff_T', \n",
    "        '_depth_7_subsample-data_1.0_subsample-feat_1.0', 'Lactate_Measured', '1111'), 'test_patient_ids.pkl')\n",
    "assert len(np.intersect1d(test_ids[train_second_stage['idxs']], test_ids[test_second_stage['idxs']]))==0\n",
    "tr=len(train_second_stage['idxs'])\n",
    "t=len(test_second_stage['idxs'])\n",
    "print(f\"train %:{tr*100/(tr+t):.2f}, test %:{t*100/(tr+t):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "LGBM_T = loadFile(osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage', 'predict_T'),\n",
    "                  'LGBM_T.pkl')\n",
    "LGBM_D_given_T = loadFile(osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage',\n",
    "                                   'predict_D_given_T'),'LGBM_D_given_T.pkl')\n",
    "LGBM_D_and_T =loadFile(osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage', \n",
    "                                'predict_D_and_T'),'LGBM_D_and_T.pkl')\n",
    "LGBM_D_given_T_ipw = loadFile(osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage',\n",
    "                                       'predict_D_given_T_ipw'),'LGBM_D_given_T_ipw.pkl')\n",
    "LGBM_D_pseudo = loadFile(osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage', \n",
    "                                  'predict_D_pseudo'),'LGBM_D_pseudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f92ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['LGBM']\n",
    "tasks=['T', 'D|T', 'D|T_ipw', 'D_and_T', 'D_pseudo']\n",
    "clf_list=[LGBM_T, LGBM_D_given_T, LGBM_D_given_T_ipw,\n",
    "          LGBM_D_and_T, LGBM_D_pseudo]\n",
    "clf_dict={}\n",
    "i=0\n",
    "for t in tasks:\n",
    "    clf_dict[t]={}\n",
    "    for m in models:\n",
    "        clf_dict[t][m]=clf_list[i]\n",
    "        i+=1\n",
    "dict_df_labels={}\n",
    "dict_df_probs={}\n",
    "dict_df_ids={}\n",
    "dict_models={}\n",
    "probs_path=osp.join(processed_data_path, 'secondStage')\n",
    "alpha=0.1\n",
    "figsize1=(5,50)\n",
    "figsize2=(10,10)\n",
    "df_pp=pd.DataFrame({'AUC' : [],'PR':[],'BalancedAcc':[],'modelName':[],'rowName':[]})\n",
    "dict_df_labels, dict_df_probs, dict_models, df_pp = getCorr(models, tasks, \n",
    "        test_second_stage['X_T'], clf_dict, None, \n",
    "        None, dict_df_labels, dict_df_probs, \n",
    "        dict_models, df_pp, probs_path, calibrate=False, \n",
    "        figsize1=figsize1, figsize2=figsize2, alpha=alpha, test_second_stage=test_second_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Medical correlation matrix'\n",
    "corr_method=\"spearman\"\n",
    "figsize=(10, 10)\n",
    "top_adjust=0.9\n",
    "title_en=False\n",
    "plotCorr(models, dict_df_probs, title, corr_method, figsize=figsize, top_adjust=top_adjust,\n",
    "         title_en=title_en, savefig_path=osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2083822",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=r'Correlation with $p_{Y}$' '\\n' r'when $u(x)=\\alpha p_{Y_{T=1}}$'\n",
    "models=['LGBM']\n",
    "tasks=['T', 'D|T', 'D|T_ipw', 'D_and_T', 'D_pseudo']\n",
    "#        , 'product_T_D_given_T', 'D_pseudo']\n",
    "figsize=(7,5)\n",
    "# figsize=(10,7)\n",
    "top_adjust=0.9\n",
    "# tasks=['T', 'D|T']\n",
    "corr_method=stats.spearmanr\n",
    "title_en=True\n",
    "loc='lower right'\n",
    "legend_ncol=2\n",
    "plotCorr_w_Unobs(dict_df_probs, models, title, tasks, alpha=np.arange(0,1.1,0.1), corr_method=corr_method,\n",
    "                 figsize=figsize, top_adjust=top_adjust, title_en=title_en, loc=loc,\n",
    "        calibrated_p_T=calibrated_p_T[test_second_stage['idxs']],\n",
    "                 calibrated_p_D_T1=calibrated_p_D_T1[test_second_stage['idxs']], legend_ncol=legend_ncol,\n",
    "                savefig_path=osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=r'Correlation with $p_{Y}$' '\\n' r'when $u(x)=\\alpha$ is constant'\n",
    "models=['LGBM']\n",
    "# tasks=['T', 'D|T']\n",
    "corr_method=stats.spearmanr\n",
    "tasks=['T', 'D|T', 'D|T_ipw', 'D_and_T', 'D_pseudo']\n",
    "figsize=(7,5)\n",
    "# figsize=(10,7)\n",
    "title_en=True\n",
    "loc='lower right'\n",
    "legend_ncol=2\n",
    "plotCorr_w_Unobs(dict_df_probs, models, title, tasks, corr_method=corr_method,\n",
    "                 figsize=figsize, title_en=title_en, loc=loc,\n",
    "        calibrated_p_T=calibrated_p_T[test_second_stage['idxs']],\n",
    "                 calibrated_p_D_T1=calibrated_p_D_T1[test_second_stage['idxs']], legend_ncol=legend_ncol,\n",
    "                savefig_path=osp.join(processed_data_path, 'LGBM_w_feat_v2_cutoff_T', 'secondStage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266e618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3832a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs_stats=pd.DataFrame({'model' : [],'task':[],'mean':[],'std':[], 'min':[]})\n",
    "for m in models:\n",
    "    for t in tasks:\n",
    "        df_probs_stats=df_probs_stats.append({'model' : m,'task':t,'mean':dict_df_probs[m][t].mean(),\n",
    "                'std':dict_df_probs[m][t].std(), 'min':dict_df_probs[m][t].min()},ignore_index=True)\n",
    "        print(f\" mean and std for model {m} and task {t}: {dict_df_probs[m][t].mean():.3f}, {dict_df_probs[m][t].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb229a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Distribution of estimated probs'\n",
    "models=['LGBM']\n",
    "tasks=['T', 'D|T', 'D|T_ipw', 'D_and_T', 'D_pseudo']\n",
    "figsize=(10,7)\n",
    "plotDistributionProbs(dict_df_probs, models, title, tasks, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7428771",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print(f\"for model :{m}\")\n",
    "    getResiduals(dict_df_probs[m]['D_and_T'], dict_df_probs[m]['D|T'], dict_df_probs[m]['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb18881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu-benchmark",
   "language": "python",
   "name": "icu-benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
